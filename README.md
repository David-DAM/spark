# Proyecto de Apache Spark

Este proyecto contiene ejercicios prácticos de consulta utilizando Apache Spark, configuraciones para ejecutarlo en un
entorno Docker y las dependencias necesarias para ejecutarlo correctamente.

## Tabla de Contenidos

- [Requisitos Previos](#requisitos-previos)
- [Instalación](#instalación)
- [Ejercicios de Consulta](#ejercicios-de-consulta)
- [Docker](#docker)
- [Dependencias](#dependencias)
- [Contribuciones](#contribuciones)

---

## Requisitos Previos

- **Apache Spark**: Version 3.3.1.
- **Docker**: Instalado y configurado.
- **Java**: Versión 8 o superior.
- **Maven** o **Gradle** para la gestión de dependencias.

## Instalación

1. Clona el repositorio:
   ```bash
   git clone https://github.com/tu-usuario/spark-project.git
   cd spark-project
   ```
2. Instala las dependencias usando Maven:
   ```bash
   mvn clean install
   ```

## Ejercicios de Consulta

Los ejercicios están diseñados para aprender y practicar el uso de Apache Spark con diferentes tipos de datos:

## Docker

### Docker compose

El proyecto incluye un Dockerfile para facilitar la ejecución del entorno de Spark. Contiene:

- La imagen base de Apache Spark.
- Configuraciones.

## Dependencias

El proyecto utiliza las siguientes dependencias:

- **Apache Spark Core**: Para el procesamiento de datos.
- **Spark SQL**: Para consultas SQL sobre los datos.

## Contribuciones

¡Contribuciones son bienvenidas! Si tienes sugerencias, mejoras o nuevos ejercicios, abre un issue o envía un pull
request.
